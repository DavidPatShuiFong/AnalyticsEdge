---
title: "Claims Data Medicare+Medicaid"
author: "David Fong"
date: "3/14/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

*MITX Analytics Edge exercise*

## Claims Data

Sample of patients in the Medicare program (USA), which provides health insurance to Americans aged 65 years and older, as well as some younger people with certain medical conditions.

```{r}
library(tidyverse)
library(caTools)
```
```{r message = FALSE}
library(rpart)
library(rpart.plot)
```


## Data

This data comes from the DE-SynPUF dataset, published by the United States Centers for Medicare and Medicaid Services (CMS).

```{r pressure, echo=FALSE}
claims <- read.csv("ClaimsData.csv")
str(claims)
```

**reimbursement2008** is the total amount of Medicare reimbursements for this patient in 2008.

**reimbursement2009** is the total value of all Medicare reimbursements for the patient in 2009.

**bucket2008** is the cost bucket the patient fell into in 2008, and **bucket2009** is the cost bucket
the patient fell into in 2009. These cost buckets are defined using the thresholds determined
by D2Hawkeye.

* 1st bucket < $3000
* 2nd bucket $3000-$8000
* 3rd bucket $8000-$19000
* 4th bucket $19000-$55000
* 5th bucket $55000+

```{r}

table(claims$bucket2009)/nrow(claims)

barplot(table(claims$bucket2009))

```

## Create training and test set

```{r}
set.seed(88)
spl = sample.split(claims$bucket2009, SplitRatio = 0.6) # use library caTools
claimstrain <- subset(claims, spl == TRUE)
claimstest <- subset(claims, spl == FALSE)
```

```{r}
summary(claimstrain)
```

Proportion of people in training set with diagnosis code for diabetes

```{r}
table(claimstrain$diabetes)/nrow(claimstrain)
```

## Baseline model

Baseline model is last year's claim bucket (2008) predicts this year's claim bucket (2009).

```{r}
baseline_table <- table(claimstest$bucket2009, claimstest$bucket2008)

baseline_table

# Accuracy is the number of correct predictions.
# The correct predictions are where 'row' matches 'column'
# i.e. the entries in the diagonal
paste('Accuracy:', (sum(diag(baseline_table)))/nrow(claimstest))
```

## Penalty matrix (for Hawkeye model)

```{r}
PenaltyMatrix = matrix(c(0,1,2,3,4,2,0,1,2,3,4,2,0,1,2,6,4,2,0,1,8,6,4,2,0), byrow = TRUE, nrow = 5)

PenaltyMatrix
```

Actual outcomes on left, predicted outcomes are on top.
Biggest penalty when a low cost bucket is predicted, but the actual outcome is a high cost bucket.
There is a penalty for predicting a high cost bucket, when the actually is a low cost bucket, but penalty is not so bad.


### Penalty error for baseline model

```{r}
as.matrix(baseline_table)*PenaltyMatrix

paste('Penalty error:', sum(as.matrix(baseline_table)*PenaltyMatrix)/nrow(claimstest))

```

## Second baseline model

Predict the most frequent outcome for all observations, which is cost bucket '1'.

```{r}
baseline2_table <- table(claimstest$bucket2009, seq(from = 1, to = 1, length.out = nrow(claimstest)))
baseline2_table
```

```{r}
baseline2_penalty <- as.matrix(baseline2_table) * PenaltyMatrix[,1]
baseline2_penalty

paste('Accuracy :', baseline2_table[1]/nrow(claimstest))
paste('Penalty error:', sum(baseline2_penalty)/nrow(claimstest))
```

## Classification and Regression Tree (CART) prediction

```{r}
ClaimsTree <- rpart(bucket2009 ~ age + arthritis + alzheimers + cancer + copd + depression + diabetes + heart.failure + ihd + kidney + osteoporosis + stroke + bucket2008 + reimbursement2008, 
                    data = claimstrain, method = "class", cp = 0.00005)
```

cp value was selected through cross-validation on the training set.

```{r}
prp(ClaimsTree)
```
```{r}
PredictTest <- predict(ClaimsTree, newdata = claimstest, type = "class")
predict_table <- table(claimstest$bucket2009, PredictTest)

predict_table
paste('Accuracy:', (sum(diag(predict_table)))/nrow(claimstest))

```

```{r}
as.matrix(predict_table)*PenaltyMatrix

paste('Penalty error:', sum(as.matrix(predict_table)*PenaltyMatrix)/nrow(claimstest))
```

CART model has better accuracy, but does worse with penalty error, compared to first baseline model.
This is because CART assigns a value of '1' to all errors, and did not weight the errors in the same way as the PenaltyMatrix.

## CART model with custom loss matrix

```{r}
ClaimsPenaltyTree <- rpart(bucket2009 ~ age + arthritis + alzheimers + cancer + copd + depression + diabetes + heart.failure + ihd + kidney + osteoporosis + stroke + bucket2008 + reimbursement2008,
                           data = claimstrain, method = "class", cp = 0.00005,
                           parms = list(loss = PenaltyMatrix)) # define penalty matrix
```

```{r}
prp(ClaimsPenaltyTree)
```

```{r}
PredictPenaltyTest <- predict(ClaimsPenaltyTree, newdata = claimstest, type = "class")
predictpenalty_table <- table(claimstest$bucket2009, PredictPenaltyTest)

predictpenalty_table
paste('Accuracy:', (sum(diag(predictpenalty_table)))/nrow(claimstest))

as.matrix(predictpenalty_table)*PenaltyMatrix

paste('Penalty error:', sum(as.matrix(predictpenalty_table)*PenaltyMatrix)/nrow(claimstest))
```

Lower accuracy than baseline, but better (lower) penalty score as well.